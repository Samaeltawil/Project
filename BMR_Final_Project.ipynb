{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Mobile Robotics - Thymio Project (Fall 2023-2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Executed By: Nina, Sama Eltawil, Asma ,  Corentin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#I.-Introduction\" data-toc-modified-id=\"I.-Introduction-1\">I. Introduction</a></span></li><li><span><a href=\"#II.-Implementation-with-video-input\" data-toc-modified-id=\"II.-Implementation-with-video-input-2\">II. Conventional Implementation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Software-&amp;-Hardware-Setup\" data-toc-modified-id=\"Software-&amp;-Hardware-Setup-2.1\"> Model Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-libraries\" data-toc-modified-id=\"Import-libraries-2.1.1\">Used Libraries</a></span></li></li><li><span><a href=\"#Method-Overview\" data-toc-modified-id=\"Method-Overview-2.2\">Method Overview</a></span></li><li><span><a href=\"#Global-Map-Setup-&amp;-Construction-via-Image-Processing\" data-toc-modified-id=\"Global-Map-Setup-&amp;-Construction-via-Image-Processing-2.3\">Global Map Setup &amp; Construction via Image Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Map-setup\" data-toc-modified-id=\"Map-setup-2.3.1\">Map setup</a></span></li><li><span><a href=\"#Implemetation-details\" data-toc-modified-id=\"Implemetation-details-2.3.2\">Implemetation details</a></span></li><li><span><a href=\"#Parameter-settings\" data-toc-modified-id=\"Parameter-settings-2.3.3\">Parameter settings</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.3.4\">Functions</a></span></li><li><span><a href=\"#Examples\" data-toc-modified-id=\"Examples-2.3.5\">Examples</a></span></li></ul></li><li><span><a href=\"#Global-Planning\" data-toc-modified-id=\"Global-Planning-2.4\">Global Planning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Implemetation-details\" data-toc-modified-id=\"Implemetation-details-2.4.1\">Implemetation details</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.4.2\">Functions</a></span></li><li><span><a href=\"#Examples\" data-toc-modified-id=\"Examples-2.4.3\">Examples</a></span></li></ul></li><li><span><a href=\"#Global-Control\" data-toc-modified-id=\"Global-Control-2.5\">Global Control</a></span><ul class=\"toc-item\"><li><span><a href=\"#Implemetation-details\" data-toc-modified-id=\"Implemetation-details-2.5.1\">Implemetation details</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2.5.2\">Parameters</a></span></li><li><span><a href=\"#Function\" data-toc-modified-id=\"Function-2.5.3\">Function</a></span></li></ul></li><li><span><a href=\"#Local-Navigation\" data-toc-modified-id=\"Local-Navigation-2.6\">Local Navigation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Implemetation-details\" data-toc-modified-id=\"Implemetation-details-2.6.1\">Implemetation details</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2.6.2\">Parameters</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.6.3\">Functions</a></span></li></ul></li><li><span><a href=\"#Overall-Implementation\" data-toc-modified-id=\"Overall-Implementation-2.7\">Overall Implementation</a></span></li></ul></li><li><span><a href=\"#III.-Implementation-without-video-input\" data-toc-modified-id=\"III.-Implementation-without-video-input-3\">III. Kidnapping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Method-Overview\" data-toc-modified-id=\"Method-Overview-3.1\">Method Overview</a></span></li><li><span><a href=\"#Basic-Setup\" data-toc-modified-id=\"Basic-Setup-3.2\">Basic Setup</a></span></li><li><span><a href=\"#Navigation-with-Kalman-Filtering\" data-toc-modified-id=\"Navigation-with-Kalman-Filtering-3.3\">Navigation with Kalman Filtering</a></span></li><li><span><a href=\"#Global-Map-Setup\" data-toc-modified-id=\"Global-Map-Setup-3.4\">Global Map Setup</a></span></li><li><span><a href=\"#Towards-the-goal\" data-toc-modified-id=\"Towards-the-goal-3.5\">Towards the goal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-case1\" data-toc-modified-id=\"Test-case1-3.5.1\">Test case1</a></span></li><li><span><a href=\"#Test-case2\" data-toc-modified-id=\"Test-case2-3.5.2\">Test case2</a></span></li><li><span><a href=\"#Test-case3\" data-toc-modified-id=\"Test-case3-3.5.3\">Test case3</a></span></li></ul></li></ul></li><li><span><a href=\"#IV.-Reference\" data-toc-modified-id=\"IV.-Reference-4\">IV. Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T13:27:12.242492Z",
     "start_time": "2020-11-29T13:27:12.218370Z"
    }
   },
   "source": [
    "This project is of a multi-disciplinary nature combining various approaches to acheive the autonomous navigation of the Thymio from a start point to a specified goal in a map consiting of fixed obstacles. Through its trajectory, the Thymio must also be able to locally avoid dynamically placed while navigation on its optimal path and still reach the goal within the optimal path possible. To acheive this required outcome, several modules needed to come together such as:\n",
    "- *Computer Vision*\n",
    "- *Local Navigation and Obstacle Avoidance*\n",
    "- *Global Navigation & Path-Planning*\n",
    "- *Filtering*\n",
    "- *Control*\n",
    "\n",
    "\n",
    "\n",
    "**To get an overview about the whole implementation, a demo video is available [Through](https://drive.google.com/file/d/1wbtolQur5SVBcemI5H8u9ayeaPjNCPrn/view).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Conventional Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T16:46:20.191281Z",
     "start_time": "2020-12-05T16:46:19.788039Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import serial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import math\n",
    "import time\n",
    "import serial\n",
    "import tqdm\n",
    "import scipy\n",
    "import vision_func\n",
    "import cv2\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "# Thymio Python bridge\n",
    "from Thymio import Thymio\n",
    "# for visualization\n",
    "from viz_utilis import plotPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement:**\n",
    "In the vision-guided version, Thymio should navigate from any possible start position to any reachable end position in a webcam-supervised arena with various obstacles. During the motion, new obstacles are added to test the local navigation and replanning. The robot can also recover from the kidnap.\n",
    "\n",
    "**Final implementation:**\n",
    "Thymio will first read a global map from processed images obtained from the webcam. The global navigation is based on the A* algorithm. If unexpected obstacles are detected in the planned path, local avoidance is triggered to avoid the obstacle ahead via horizontal proximity sensors and send a replanning flag. Likewise, a replanning flag is also issued to recalculate the optimal path if the robot detects the kidnap via ground proximity sensors.\n",
    "\n",
    "![](./img/VGV_Workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Map Setup & Perception Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate an environment with walls in which Thymio will roam around. We use a drawer with a maximum size of 1000x600 mm for the robot arena. As obstacles, we selected an empty beverage box folded with red-colored paper, which will be easier to recognize in the image processing.Besides, the webcam is fixed at a distance of 1m from the ground\n",
    "\n",
    "In this part, Wireless Thymio is connected to the computer via the dongles.\n",
    "\n",
    "![](./img/with_Small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T13:57:42.902833Z",
     "start_time": "2020-11-29T13:57:42.891110Z"
    }
   },
   "source": [
    "#### Implemetation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vision method is strongly dependent on the map data, which can be updated continuously from the video. The construction of a global map consists of the following steps:\n",
    "\n",
    "1. The raw images are sampled at a given frequency from the webcam.\n",
    "2. The raw images are calibrated using a camera matrix and transformed using the four corner marks in the arena.\n",
    "3. Multiple color masks are applied to the transformed image to distinguish the target position, thymio (front and rear) and obstacles.\n",
    "4. The obstacle mask is dilated and rasterized to provide a grid-wise occupancy map for the A* algorithm.\n",
    "5. The obtained occupancy map and starting-end pose are saved and updated with a given frequency.\n",
    "\n",
    "**Note:** The global map construction is running independently and simultaneously with other modules that control the Thymio. It will always try to update the map to the latest. If the map is not recognizable (interference of humans like putting a hand over Thymio), the global map will not be updated. The last successfully constructed map will be passed into path planning.\n",
    "\n",
    "- **Hardware**\n",
    "\n",
    "    Our group uses the \"Trust Spotlight Pro\" webcam. For more details, please refer to https://www.digitec.ch/de/s1/product/trust-spotlight-pro-130mpx-webcam-5707237.\n",
    "    \n",
    "| Hardware                | Parameters                                                      | Image | \n",
    "| :------------------- | :------------------------------------------------------------ | :----------- | \n",
    "| [\"Trust Spotlight Pro\" webcam](https://www.digitec.ch/de/s1/product/trust-spotlight-pro-130mpx-webcam-5707237)   | **Connection**: USB <br> **Pixel resolution**: 1280 x 1024 pixels <br> **Refresh rate**: 30FPS | ![](https://static.digitecgalaxus.ch/Files/1/9/7/8/0/6/0/3/16428_pictures_product_visual_1.png?impolicy=ProductTileImage&resizeWidth=436&resizeHeight=335&quality=high&cropWidth=436&cropHeight=335)         | \n",
    "\n",
    "\n",
    "- **Input**\n",
    "\n",
    "    - Raw image captured from camera\n",
    "    - Grid size to be used for robot movement (for A* algorithm)\n",
    "    - Color HSV values that helps define the map (this is sensitive to light and needs to be calibrated after setting environment)\n",
    "\n",
    "- **Output**\n",
    "\n",
    "    - Global map in the form of npy array that marks all occupancy with 1 and vacanncy with 0\n",
    "    - Starting pose and end position of the Thymio in the form of npy\n",
    "\n",
    "- **Limitations**\n",
    "\n",
    "    - The color masks are rather sensitive to lighting conditions and hyperparameters need to be calibrated each time when the environment is setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Key parameters**\n",
    "\n",
    "    - Related to algorithms\n",
    "\n",
    "| Name                | Meaning                                                      | Type |\n",
    "| :------------------ | :----------------------------------------------------------- | :--- |\n",
    "| `mtx`               | Camera matrix of the calibrated webcam                       | Float array (3x3)|\n",
    "| `dist`              | Distortion coefficients of the calibrated webcam             | Float array (1x5)|\n",
    "| `real_height`       | Height of the arena between 2 markers (default 56 cm)| Int |\n",
    "| `real_width`        | Width of the arena between 2 markers (default 80 cm)| Int |\n",
    "| `COLOR_lower`       | Lower HSV threshold of the COLOR mask | Int Array (1x3) |\n",
    "| `COLOR_upper`       | Upper HSV threshold of the COLOR mask | Int Array (1x3) |\n",
    "| `time_interval`     | Time interval between the updates of captured img            | Float |\n",
    "| `ext_pixels`        | Dilation pixels of the obstacles (Measured : 7 pixels = 1 cm) | Float |\n",
    "| `offset_thymio`     | Offset of the rotation center of Thymio to the vision identified center | Tuple |\n",
    "| `grid_size`         | Size of the rasterizing grid (default 4 cm) | Int |\n",
    "| `grid_array_output` | Rasterzied occupancy map with 1 for occupied and 0 for vacnt | Int array (nxn)|\n",
    "| `grid_array_start`  | Coordinate of Thymio start point in the rasterized map | Tuple |\n",
    "| `grid_array_end`    | Coordinate of Thymio end point in the rasterized map | Tuple |\n",
    "| `start_direction`   | Direction vector of Thymio (coordinate same as image coordinate) | Tuple |\n",
    "\n",
    "- Color mask table\n",
    "\n",
    "| Color     | Used for    | Lower bounds (default) | Upper bounds (default) |\n",
    "| :---------| :--------   | :----------- | :----------- |\n",
    "| `pink`    | 4 Corner markers of arena | [100, 95, 110] | [150, 155, 200]|\n",
    "| `yellow`  | End position of Thymio    | [85, 100, 170] | [120, 125, 210]|\n",
    "| `red `    | Obstacles                 | [100, 130, 145]| [132, 170, 200]|\n",
    "| `orange`  | Obstacles (back up)       | [95, 124, 165] | [115, 175, 205]|\n",
    "| `green`   | front of Thymio           | [30, 130, 90]  | [60, 175, 120] |\n",
    "| `blue`    | rear of Thymio            | [15, 180, 110] | [25, 230, 155] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_thymio = (9, 25) #pixel offset of Thymio to the center position (turning axis)\n",
    "ext_pixels = 42  # Dilate diameter of obstacles where 42 pixel equals 6 cm in the given scene setting\n",
    "grid_size = 4 #cm size of grid\n",
    "real_height = 56 #cm size of arena\n",
    "real_width = 80 #cm size of arena\n",
    "#All bondaries for color map is saved in vision_func.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Input | Output |\n",
    "|------|------|------|\n",
    "|   transform_img  | (Raw image from camera) | (Transformed image with only the zone of arena)\n",
    "|   color_mask  | (Transformed image) | (Raw obstacle mask, Thymio start, Thymio target, Thymio pose)\n",
    "|   dilate_obstacle  | (Raw obstacle mask, dilate diameter in pixel) | (Obstacle mask dilated with the Thymio radius and corrected with the walls(drawer bounds))\n",
    "|   rasterize  | (Dilated obstacle mask, arena width, arena height, grid size, start point,target point) | (Grided obstacle map, grided starting point, grided target point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_raw_img = cv2.imread(\"example_raw.jpg\")\n",
    "plt.imshow(cv2.cvtColor(example_raw_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Calibrated raw image from webcam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_img = vision_func.transform_img(example_raw_img)\n",
    "plt.imshow(cv2.cvtColor(warped_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Transformed image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[obstacles_mask,start_point,end_point,start_direction] = vision_func.color_mask(warped_img,offset_thymio)\n",
    "\n",
    "temp = obstacles_mask.copy()\n",
    "temp = cv2.circle(temp, (start_point[1],start_point[0]), 5, (80,0,0), 5)\n",
    "temp = cv2.circle(temp, (end_point[1],end_point[0]), 5, (160,0,0), 5)\n",
    "plt.imshow(temp)\n",
    "plt.title('Color mask')\n",
    "print(f'startpoint at {start_point}, endpoint at {end_point}, direction vector is {start_direction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacles_mask_dilated = vision_func.dilate_obstacle(obstacles_mask,ext_pixels)\n",
    "plt.imshow(obstacles_mask_dilated,cmap = 'gray')\n",
    "plt.title('Dilated obstacle map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[grid_output,grid_array_output,grid_array_start,grid_array_end] = vision_func.rasterize(obstacles_mask_dilated,real_width,real_height,grid_size,start_point,end_point)\n",
    "plt.imshow(grid_array_output, cmap = \"gray\")\n",
    "plt.title('Grided obstacle map')\n",
    "print(f'grid_start point at {grid_array_start}, grid_end_point at {grid_array_end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implemetation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A* algorithm is used for global planning in this project. For convenience when implementing filter, only four movements are possible, which is respectively (1,0), (-1,0), (0,1), (0,-1). Knowing the start point, the goal point and the whole map, the algorithm can then compute the optimal path to reach the destination.\n",
    "\n",
    "- **Input**\n",
    "\n",
    "    - **start** : a tuple contains the coordinates of start point (e.g. (11, 21))\n",
    "    - **goal** : a tuple contains the coordinates of goal point (e.g. (4, 34))\n",
    "    - **occupancy_grid** : an array contains the information of our map\n",
    "    - **Height** : the max X value a grid can take. In practice, it means the number of grids along the North and South direction\n",
    "    - **Len** : the max Y value a grid can take. In practice, it means the number of grids along the East and West direction\n",
    "              \n",
    "\n",
    "\n",
    "- **Output**\n",
    "\n",
    "    - **optimal_path** : a list of tuples containing the coordinates of all points along the optimal path\n",
    "    - **control_guide** : a list of tuples containing which direction to move along the optimal path. Only four directions is included in this function. (1,0) means moving South, (0,1) means moving East and so on.\n",
    "\n",
    "- **Limitations**\n",
    "\n",
    "    - The time complexity of the A* algorithm depends on the heuristic and is nonlinear. Thus, it brings a heavy computational burden if the start point is far from the goal point. In our experiment, the total size of the grid size is small ( 14 x 20 ). So, the algorithm can work fine. However, the worst running time is 41s for larger sizes (60 x 100).\n",
    "    - Only four possible directions are available for convenience when implementing a filter. This limitation could be improved by adjusting the variable **movements** defined in the function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T18:08:43.140405Z",
     "start_time": "2020-12-05T18:08:43.105357Z"
    }
   },
   "outputs": [],
   "source": [
    "def A_Star_4_direction(start, goal, occupancy_grid, Height, Len):\n",
    "    \n",
    "    # List of all coordinates in the grid\n",
    "    x,y = np.mgrid[0:Height:1, 0:Len:1]\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "    pos = np.reshape(pos, (x.shape[0]*x.shape[1], 2))\n",
    "    coords = list([(int(x[0]), int(x[1])) for x in pos])\n",
    "    \n",
    "    # Define the heuristic, distance to goal ignoring obstacles\n",
    "    h = np.linalg.norm(pos - goal, axis=-1)\n",
    "    h = dict(zip(coords, h))\n",
    "\n",
    "    # Check if the points are inside the map\n",
    "    for point in [start, goal]:\n",
    "        assert point[0]>=0 and point[1]>=0 and point[0]<Height and point[1]<Len, \"start or end goal not contained in the map\"\n",
    "    \n",
    "    # Check if the points are in the free spaces\n",
    "    if occupancy_grid[start[0], start[1]]:\n",
    "        raise Exception('Start node is not traversable')\n",
    "\n",
    "    if occupancy_grid[goal[0], goal[1]]:\n",
    "        raise Exception('Goal node is not traversable')\n",
    "    \n",
    "    # define the four possible movements\n",
    "    s2 = math.sqrt(2)\n",
    "    movements = [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0)]\n",
    "    \n",
    "    # The set of visited nodes that need to be expanded.\n",
    "    # Initially, only the start node is known.\n",
    "    openSet = [start]\n",
    "    \n",
    "    # The set of visited nodes that no longer need to be expanded.\n",
    "    # It contains the list of variables that have already been visited \n",
    "    closedSet = []\n",
    "\n",
    "    # For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start to n currently known.\n",
    "    cameFrom = dict()\n",
    "\n",
    "    # For node n, gScore[n] is the cost of the cheapest path from start to n currently known.\n",
    "    gScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    gScore[start] = 0\n",
    "\n",
    "    # For node n, fScore[n] := gScore[n] + h(n). \n",
    "    fScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    fScore[start] = h[start]\n",
    "\n",
    "    \n",
    "    while len(openSet)!=0: \n",
    "        \n",
    "        #find the unvisited node having the lowest fScore[] value\n",
    "        fScore_openSet = {key:val for (key,val) in fScore.items() if key in openSet}\n",
    "        current = min(fScore_openSet, key=fScore_openSet.get)\n",
    "        del fScore_openSet\n",
    "        \n",
    "        #If the goal is reached, reconstruct and return the obtained path and control guide\n",
    "        if current == goal:\n",
    "            optimal_path = [current]\n",
    "            control_guide = []\n",
    "            while current != start:\n",
    "                previous=current\n",
    "                current=cameFrom[current]\n",
    "                optimal_path.insert(0,current)\n",
    "                control_guide.insert(0,(previous[0]-current[0],previous[1]-current[1]))\n",
    "            return optimal_path, control_guide\n",
    "                \n",
    "        \n",
    "        openSet.remove(current)\n",
    "        closedSet.append(current)\n",
    "\n",
    "        # If the goal was not reached, search for each neighbor of current:\n",
    "        for dx, dy, deltacost in movements: \n",
    "            neighbor = (current[0]+dx, current[1]+dy)\n",
    "            # if the node is not in the map, skip\n",
    "            if (neighbor[0] >= Height) or (neighbor[1] >= Len) or (neighbor[0] < 0) or (neighbor[1] < 0):\n",
    "                continue\n",
    "            \n",
    "            # if the node is occupied or has already been visited, skip\n",
    "            if (occupancy_grid[neighbor[0], neighbor[1]]) or (neighbor in closedSet):\n",
    "                continue\n",
    "            \n",
    "            # compute the cost to reach the node through the given path\n",
    "            tentative_gScore = deltacost + gScore[current] \n",
    "            \n",
    "            # Add the neighbor list of nodes who's neighbors need to be visited\n",
    "            if neighbor not in openSet:\n",
    "                openSet.append(neighbor)\n",
    "            \n",
    "            # If the computed cost is the best one for that node, then update the costs and \n",
    "            # node from which it came\n",
    "            if tentative_gScore < gScore[neighbor]:\n",
    "                cameFrom[neighbor] = current\n",
    "                gScore[neighbor] = tentative_gScore\n",
    "                fScore[neighbor] = gScore[neighbor] + h[neighbor]\n",
    "\n",
    "    # Open set is empty but goal was never reached\n",
    "    print(\"No path found to goal\")\n",
    "    return [], [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_eg = 50\n",
    "w_eg = 30\n",
    "\n",
    "np.random.seed(0)\n",
    "generate_eg = np.random.rand(h_eg,w_eg) * 20\n",
    "\n",
    "limit = 12\n",
    "map_eg = generate_eg.copy()\n",
    "map_eg[generate_eg>limit] = 1\n",
    "map_eg[generate_eg<=limit] = 0\n",
    "plt.imshow(map_eg.transpose(),cmap=colors.ListedColormap(['white', 'green']))\n",
    "\n",
    "start_eg = (1,2)\n",
    "goal_eg = (42,28)\n",
    "\n",
    "path_eg, control_guide_eg = A_Star_4_direction(start_eg, goal_eg, map_eg, h_eg,w_eg)\n",
    "path_eg = np.array(path_eg).reshape(-1, 2).transpose()\n",
    "\n",
    "plt.plot(path_eg[0], path_eg[1], color = 'blue');\n",
    "plt.scatter(start_eg[0], start_eg[1], marker=\"o\", color = 'red', s=200);\n",
    "plt.scatter(goal_eg[0], goal_eg[1], marker=\"o\", color = 'yellow', s=200);\n",
    "plt.title(\"Green represents obstacle, Blue is the global optimal path\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implemetation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function **Control** controls Thymio to move along the global optimal path obtained by function **Visibility Graph**. This will applied by simply deploying a proportional gain to the error difference between the Thymio's current orientation and the goal's position.\n",
    "- **Input**\n",
    "\n",
    "    - **control_guide** : one of the outputs of A* algorithm ( a list of tuple)\n",
    "    - **curr_ang** : a float meaning the current angle of Thymio\n",
    "    - **idx** : an int telling Thymio which step of the global optimal path to take. e.g. If idx = 3 and control_guide[3] = (0,1), Thymio will go along (0,1) and move across one grid\n",
    "\n",
    "\n",
    "- **Limitations**\n",
    "\n",
    "    - Very sensitive to the accuracy of the current angle obtained by the camera. If the camera is not precise enough, Thymio will rotate to a wrong direction.\n",
    "    - Without filter here, the global controller do not realize it even if Thymio deviates from the supposed path. Thus, some kind of closed-loop control is applied in the **Overall Implementation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Key parameters**\n",
    "\n",
    "| Name             | Meaning                                       | Type (Unit) | Global |\n",
    "| :--------------- | :-------------------------------------------- | :---------- | :----- |\n",
    "| forward_duration | Time duration for moving forward              | Int         | Yes    |\n",
    "| run_speed        | Speed of the wheels when moving forward       | Int         | Yes    |\n",
    "| run_offset       | Offset for the difference speed of two wheels | Int         | Yes    |\n",
    "| rot_duration     | Time duration for rotating                    | Float       | Yes    |\n",
    "| rot_speed        | Speed of the wheels when rotating             | Int         | Yes    |\n",
    "| basic_moves      | Four possible movements of Thymio             | List        | No     |\n",
    "| basic_orients    | Orient of each movement in **basic_moves**   | List        | No     |\n",
    "| basic_angle      | Angle of each movement in **basic_moves**     | List        | No     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P Controller Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T17:27:49.190583Z",
     "start_time": "2020-12-04T17:27:49.173379Z"
    }
   },
   "outputs": [],
   "source": [
    "def p_controller(current_pos, current_gamma, goal_pos):\n",
    "    P_angle = 2 #to be tuned\n",
    "    P_velocity = 0.1\n",
    "    \n",
    "    diff_vector = np.array([goal_pos[0][0] - current_pos[0][0],goal_pos[1][0] - current_pos[1][0]]) #2x1\n",
    "    distance = math.sqrt(diff_vector[0]**2 + diff_vector[1]**2)\n",
    "    #print(f\"my position:{current_pos} - goal_pos:{goal_pos} - difference vector:{diff_vector} - distance: {distance}\")\n",
    "\n",
    "    alpha = math.atan2(diff_vector[1], diff_vector[0])\n",
    "    omega = P_angle * (alpha - current_gamma)\n",
    "    velocity = P_velocity*np.linalg.norm(diff_vector)\n",
    "    \n",
    "    return velocity, omega\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Global Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T17:47:04.516350Z",
     "start_time": "2020-12-04T17:47:04.495668Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_threshold = 0.1\n",
    "    \n",
    "def control(Goal_nodes): \n",
    "    current_pos = np.array([[0],[0]]) #kalman filter values 2x1\n",
    "    current_gamma = 0\n",
    "    \n",
    "    positions=[]\n",
    "    \n",
    "    max_iter = 0\n",
    "    \n",
    "    while (max_iter < 200):\n",
    "\n",
    "        if ((np.linalg.norm(current_pos - Goal_nodes[:, 1])) > distance_threshold):\n",
    "            goal_pos = ([[Goal_nodes[0,1]],[Goal_nodes[1,1]]])\n",
    "            velocity, omega = p_controller(current_pos, current_gamma, goal_pos)\n",
    "            \n",
    "            current_pos, current_gamma = simulate_robot_motion(current_pos, current_gamma, velocity, omega)\n",
    "            \n",
    "            positions.append((current_pos[0], current_pos[1]))\n",
    "\n",
    "        else: \n",
    "            print(\"goal reached\")\n",
    "            \n",
    "        max_iter += 1\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trajectory Following Simulation + Initialization \"Independant Implementation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_robot_motion(current_pos, current_gamma, velocity, omega, dt=0.2):\n",
    "    # Update the robot's position based on the simulated motion\n",
    "    # Use a simple kinematic model (you may need to adapt this based on your robot's dynamics)\n",
    "    # Example: Update x, y, and theta based on wheel velocities\n",
    "    x, y = current_pos[0, 0], current_pos[1, 0]\n",
    "\n",
    "    # Update x, y, and theta based on wheel velocities\n",
    "    x_next = x + velocity * math.cos(current_gamma) * dt\n",
    "    y_next = y + velocity * math.sin(current_gamma) * dt\n",
    "    thymio_orient_next = current_gamma + omega * dt\n",
    "\n",
    "    return np.array([[x_next], [y_next]]), thymio_orient_next\n",
    "\n",
    "\n",
    "#initalizations\n",
    "Goal_nodes = np.array([[0,1,2,2.5,3.5],[0.0,0.5,2,3,3.5]]) #2x5\n",
    "current_pos = np.array([[0], [0]]) #initial position\n",
    "positions = []\n",
    "\n",
    "# Main simulation loop\n",
    "positions = control(Goal_nodes)\n",
    "x_plot,  y_plot = zip(*positions)\n",
    "#print(positions)\n",
    "plt.scatter(x_plot, y_plot, c='green', label='Live Position')\n",
    "plt.scatter(Goal_nodes[0, :], Goal_nodes[1, :])\n",
    "plt.plot(Goal_nodes[0, :], Goal_nodes[1, :], marker='o', linestyle='-', color='black')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Thymio Robot Motion - Random Lines')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implemetation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In our setup, there are two types of obstacles to avoid:** \\\n",
    "\\\n",
    "**-Fixed Obstacles:** These obstacles are predefined before even starting the trajectory planning and can be detected by the camera. Therefore, they are already accounted for in the global path planning algorithm. \\\n",
    "\\\n",
    "**-Random Obstacles:** These obstacles can be added at anytime during the trajectory following and they must be detected and avoided locally by the Thymio. To address this challenge, we will solely rely on the proximity sensors that the Thymio is equipped with to detect how far are the obstacles, given they are 3D, and steer away by entering local navigation according to the predefined thresholds.\\\n",
    "\\\n",
    "The Local navigation is based on an artifical neural networks algorithm with a memory and the weights are tuned according to the Thymio. The output of the function is some motor control commands to steer the Thymio away from the local obstacles until it's safe and then it returns back to the global navigation.\n",
    "\n",
    "- **Input**\n",
    "\n",
    "    - Horizontal proximity sensor values\n",
    "\n",
    "\n",
    "- **Output**\n",
    "\n",
    "    - Motor Control for Right and Left Wheels for local obstacle avoidance\n",
    "\n",
    "- **Limitations**\n",
    "\n",
    "    - The physical triangualr obstacles were fixed using a cylinder in the middle which made it harder for the thymio to detect the edges, it just detests the center of the object. To account for this, we need to decrease the distance threshold to steer further away from the center of the obstacle to avoid hitting the obstacle edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Key parameters**\n",
    "\n",
    "| Name                | Meaning                                                      | Type (Unit)\n",
    "| :------------------- | :------------------------------------------------------------ | :----------- \n",
    "| `Up_threshold`       | Thresholds to steer away from obstacles ahead and enter the local navigation                  | Int         \n",
    "| `Low_threshold`      | Thresholds indicating the Thymio is far from the obstacle and we can go back to global path following              | Int        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T17:29:30.748904Z",
     "start_time": "2020-12-04T17:29:30.738518Z"
    }
   },
   "outputs": [],
   "source": [
    "## Parameters for local navigation\n",
    "Up_threshold = 3500\n",
    "Low_threshold = 2300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T17:29:32.085940Z",
     "start_time": "2020-12-04T17:29:32.065940Z"
    }
   },
   "outputs": [],
   "source": [
    "def state_switch(state, dist):\n",
    "    if state == 1: # We're in Global Navigation\n",
    "        if (dist[0] > Up_threshold) or (dist[1] > Up_threshold) or (dist[2] > Up_threshold) or (dist[3] > Up_threshold) or (dist[4] > Up_threshold):\n",
    "            state = 2 # Switch to Local Navigation to avoid obtstacle. If obstacle is detected at any of the prox sensors.\n",
    "            \n",
    "    elif state == 2: # We're in Local Navigation\n",
    "        if (dist[0] < Low_threshold) and (dist[1] < Low_threshold) and (dist[2] < Low_threshold) and (dist[3] < Low_threshold) and (dist[4] < Low_threshold):\n",
    "            state = 1 # Go back to Global Navigation. If obstacle is far wrt to all prox sensors.\n",
    "            \n",
    "    return state        \n",
    "            \n",
    "\n",
    "def obs_avoid(prox_horizontal, y):\n",
    "    \n",
    "    # ANN Obstacle Avoidance Approach\n",
    "    w_l = [40,  20, -20, -20, -40,  30, -10, 8, 0]\n",
    "    w_r = [-40, -20, -20,  20,  40, -10, 30, 0, 8]\n",
    "\n",
    "    # Scale factors for sensors and constant factor\n",
    "    sensor_scale = 500\n",
    "    constant_scale = 20\n",
    "    \n",
    "    x = [0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    # Memory\n",
    "    x[7] = y[0]//constant_scale\n",
    "    x[8] = y[1]//constant_scale\n",
    "        \n",
    "    for i in range(7):\n",
    "        # Get and scale inputs\n",
    "        x[i] = prox_horizontal[i] // sensor_scale\n",
    "        \n",
    "    y = [0,0]    \n",
    "        \n",
    "    for i in range(len(x)):    \n",
    "        # Compute outputs of neurons and set motor powers\n",
    "        y[0] = y[0] + x[i] * w_l[i]\n",
    "        y[1] = y[1] + x[i] * w_r[i]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independant Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0, 0]\n",
    "state = 1\n",
    "\n",
    "while state:\n",
    "    prox_horizontal = list(node.v.prox.horizontal)\n",
    "    motors = obs_avoid(prox_horizontal, y)\n",
    "    aw(node.send_events({\"moveThymio\": [motors[0], motors[1]]}))\n",
    "\n",
    "    # Check a condition to exit the loop\n",
    "    if (state == 0):\n",
    "        state = 0  # or use break to exit the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Real-time processing from webcam\n",
    "\n",
    "   Due to the characteristics of the notebook, the following code will run separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:21:09.361990Z",
     "start_time": "2020-12-05T20:21:09.349889Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('undist_params.p', 'rb') as f:  # calibrating matrix\n",
    "#     x = pickle.load(f)\n",
    "#     mtx = x['mtx']\n",
    "#     dist = x['dist']\n",
    "#     time_interval = 0.5 # updating frequency\n",
    "#     # read the raw image of camera\n",
    "#     cap = cv2.VideoCapture(1)\n",
    "#     time.sleep(1)  # wait for the webcam to initialize\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     while (1):  # loop\n",
    "#         sleep(time_interval)\n",
    "#         try:\n",
    "#             ret, frame = cap.read()\n",
    "#             frame = cv2.undistort(frame, mtx, dist, None, mtx)\n",
    "#             ###other IP functions and map exporting\n",
    "#             ###get grid_array_start, start_direction, grid_array_end and grid_array_output\n",
    "#             with open('./npy/points.npy', 'wb') as f:\n",
    "#                 np.save(f, [grid_array_start,start_direction,grid_array_end])\n",
    "#             with open('./npy/global_map.npy', 'wb') as f:\n",
    "#                 np.save(f, grid_array_output)\n",
    "#         except Exception as e:\n",
    "#             print(e)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map info reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "move_seq=dict(zip(basic_moves, basic_orients))\n",
    "ang_seq=dict(zip(basic_moves, basic_angle))\n",
    "h_v_flag = 1 # \n",
    "globalmap = np.load(\"./npy/global_map.npy\")\n",
    "state_array = np.load(\"./npy/points.npy\")\n",
    "curr_pos = (state_array[0,0],state_array[0,1])\n",
    "ang_vec = state_array[1]\n",
    "curr_ang = math.atan2(ang_vec[1],ang_vec[0]) # convert to degree by curr_ang * 180 / pi\n",
    "goal = (state_array[2,0],state_array[2,1])\n",
    "start = curr_pos\n",
    "plt.imshow(globalmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- planning the path & visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "h = globalmap.shape[0]\n",
    "w = globalmap.shape[1]\n",
    "#h, w = globalmap.shape()\n",
    "path, control_guide = A_Star_4_direction(curr_pos, goal, globalmap, h, w)\n",
    "idx = 0\n",
    "replan_flag = 0\n",
    "EVA = 1\n",
    "C_period = 3\n",
    "\n",
    "experi_name = \"Local_final\"\n",
    "plotPath(path, w, h, experi_name, save_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Towards goal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while abs(curr_pos[0] - goal[0]) + abs(curr_pos[1] - goal[1]) > EVA:\n",
    "    \n",
    "    # Check if thymio is kidnapped\n",
    "    g_sens=th[\"prox.ground.reflected\"]\n",
    "    if sum([int(ele < 10) for ele in g_sens]) == 2:\n",
    "        print(\"have been kidnapped\")\n",
    "        replan_flag = 1\n",
    "        time.sleep(8)\n",
    "        continue\n",
    "    \n",
    "    # Update current state\n",
    "    state_array = np.load(\"./npy/points.npy\")\n",
    "    curr_pos = (state_array[0,0],state_array[0,1])\n",
    "    print(curr_pos)\n",
    "    ang_vec = state_array[1]\n",
    "    #curr_ang = math.atan2(-ang_vec[0], ang_vec[1])\n",
    "    curr_ang = math.atan2(ang_vec[1],ang_vec[0])\n",
    "    \n",
    "    # Check if thymio is in the right position every `C_period` steps\n",
    "    if idx % C_period == C_period-1 and (abs(path[idx][0]-curr_pos[0])>1 or abs(path[idx][0]-curr_pos[0])>1):\n",
    "        print(\"Deviate from planned path. Replan!\")\n",
    "        print(path[idx])\n",
    "        print(curr_pos)\n",
    "        stopmotors()\n",
    "        replan_flag = 1\n",
    "    \n",
    "    # Replan the path\n",
    "    if replan_flag:\n",
    "        print(\"Re-calculated the optimal path\")\n",
    "        # reread global map\n",
    "        globalmap = np.load(\"./npy/global_map.npy\")\n",
    "        path, control_guide = A_Star_4_direction(curr_pos, goal, globalmap, h, w)\n",
    "        #cmap_name = 'gray_r'\n",
    "        #plotPath(path, w, h, True, cmap=plt.get_cmap(cmap_name))\n",
    "        plotPath(path, w, h, experi_name, save_flag=True)\n",
    "        plt.imshow(globalmap)\n",
    "        replan_flag = 0\n",
    "        idx = 0\n",
    "          \n",
    "    # Check if encontered obstacle\n",
    "    sens = th[\"prox.horizontal\"]\n",
    "    \n",
    "    # Check if should be in local or global navigation\n",
    "    if idx > 0:\n",
    "        print(\"Current pos\", curr_pos)\n",
    "        if (globalmap[2*path[idx][0]-path[idx-1][0],2*path[idx][1]-path[idx-1][1]] == 0) and \n",
    "            ([path[idx+1][0]-path[idx][0], path[idx+1][1]-path[idx][1]] == [path[idx][0]-path[idx-1][0], path[idx][1]-path[idx-1][1]]):\n",
    "            print(\"Next is empty\")\n",
    "            if (sum([sens[i] > threshold_loc[i] for i in range(0,5)])>0) and idx > 0:\n",
    "                case = 1  #local avoidance        \n",
    "        else: \n",
    "            case = 0  # global navigation\n",
    "    else:\n",
    "        case = 0\n",
    "    \n",
    "    # Go into global control or local navigation\n",
    "    if case == 0:\n",
    "        print(\"\\n#### Global navigation.\\n\")\n",
    "        global_controller_withvision(control_guide, curr_ang, idx)\n",
    "        idx += 1\n",
    "    elif case == 1:\n",
    "        print(\"\\n#### Entering local navigation.\\n\")\n",
    "        local_navigation(sens, threshold_loc, local_motor_speed)\n",
    "        replan_flag = 1\n",
    "        continue\n",
    "        \n",
    "print(\"Reached!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Implementation without video input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the manually set start and goal position, A* computes the optimal global path and the associated control command. After that, Thymio will move to the destination following the global path. Meanwhile, the Kalman filter estimates X-Y position combining a linear model of robot and sensor data.\n",
    "\n",
    "![](./img/VFV_Workflow_source_Small.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:54:05.788181Z",
     "start_time": "2020-12-05T19:54:04.999658Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import serial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "from Thymio import Thymio\n",
    "import math\n",
    "import time\n",
    "import scipy\n",
    "from viz_utilis import plot_est_result_xy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:54:21.319264Z",
     "start_time": "2020-12-05T19:54:21.306158Z"
    }
   },
   "outputs": [],
   "source": [
    "# By Cable\n",
    "th = Thymio.serial(port=\"COM4\", refreshing_rate=0.1)\n",
    "# By Wireless\n",
    "#th = Thymio.serial(port=\"\\\\.\\COM5\", refreshing_rate=0.1)\n",
    "#dir(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:54:23.275711Z",
     "start_time": "2020-12-05T19:54:23.242193Z"
    }
   },
   "outputs": [],
   "source": [
    "#run def A_Star_4_direction(start, goal, occupancy_grid, Height, Len)\n",
    "def A_Star_4_direction(start, goal, occupancy_grid, Height, Len):\n",
    "    \n",
    "    # List of all coordinates in the grid\n",
    "    x,y = np.mgrid[0:Height:1, 0:Len:1]\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "    pos = np.reshape(pos, (x.shape[0]*x.shape[1], 2))\n",
    "    coords = list([(int(x[0]), int(x[1])) for x in pos])\n",
    "    \n",
    "    # Define the heuristic, distance to goal ignoring obstacles\n",
    "    h = np.linalg.norm(pos - goal, axis=-1)\n",
    "    h = dict(zip(coords, h))\n",
    "\n",
    "    # Check if the points are inside the map\n",
    "    for point in [start, goal]:\n",
    "        assert point[0]>=0 and point[1]>=0 and point[0]<Height and point[1]<Len, \"start or end goal not contained in the map\"\n",
    "    \n",
    "    # Check if the points are in the free spaces\n",
    "    if occupancy_grid[start[0], start[1]]:\n",
    "        raise Exception('Start node is not traversable')\n",
    "\n",
    "    if occupancy_grid[goal[0], goal[1]]:\n",
    "        raise Exception('Goal node is not traversable')\n",
    "    \n",
    "    # define the four possible movements\n",
    "    s2 = math.sqrt(2)\n",
    "    movements = [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0)]\n",
    "    \n",
    "    # The set of visited nodes that need to be expanded.\n",
    "    # Initially, only the start node is known.\n",
    "    openSet = [start]\n",
    "    \n",
    "    # The set of visited nodes that no longer need to be expanded.\n",
    "    # It contains the list of variables that have already been visited \n",
    "    closedSet = []\n",
    "\n",
    "    # For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start to n currently known.\n",
    "    cameFrom = dict()\n",
    "\n",
    "    # For node n, gScore[n] is the cost of the cheapest path from start to n currently known.\n",
    "    gScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    gScore[start] = 0\n",
    "\n",
    "    # For node n, fScore[n] := gScore[n] + h(n). \n",
    "    fScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    fScore[start] = h[start]\n",
    "\n",
    "    \n",
    "    while len(openSet)!=0: \n",
    "        \n",
    "        #find the unvisited node having the lowest fScore[] value\n",
    "        fScore_openSet = {key:val for (key,val) in fScore.items() if key in openSet}\n",
    "        current = min(fScore_openSet, key=fScore_openSet.get)\n",
    "        del fScore_openSet\n",
    "        \n",
    "        #If the goal is reached, reconstruct and return the obtained path and control guide\n",
    "        if current == goal:\n",
    "            optimal_path = [current]\n",
    "            control_guide = []\n",
    "            while current != start:\n",
    "                previous=current\n",
    "                current=cameFrom[current]\n",
    "                optimal_path.insert(0,current)\n",
    "                control_guide.insert(0,(previous[0]-current[0],previous[1]-current[1]))\n",
    "            return optimal_path, control_guide\n",
    "                \n",
    "        \n",
    "        openSet.remove(current)\n",
    "        closedSet.append(current)\n",
    "\n",
    "        # If the goal was not reached, search for each neighbor of current:\n",
    "        for dx, dy, deltacost in movements: \n",
    "            neighbor = (current[0]+dx, current[1]+dy)\n",
    "            # if the node is not in the map, skip\n",
    "            if (neighbor[0] >= Height) or (neighbor[1] >= Len) or (neighbor[0] < 0) or (neighbor[1] < 0):\n",
    "                continue\n",
    "            \n",
    "            # if the node is occupied or has already been visited, skip\n",
    "            if (occupancy_grid[neighbor[0], neighbor[1]]) or (neighbor in closedSet):\n",
    "                continue\n",
    "            \n",
    "            # compute the cost to reach the node through the given path\n",
    "            tentative_gScore = deltacost + gScore[current] \n",
    "            \n",
    "            # Add the neighbor list of nodes who's neighbors need to be visited\n",
    "            if neighbor not in openSet:\n",
    "                openSet.append(neighbor)\n",
    "            \n",
    "            # If the computed cost is the best one for that node, then update the costs and \n",
    "            # node from which it came\n",
    "            if tentative_gScore < gScore[neighbor]:\n",
    "                cameFrom[neighbor] = current\n",
    "                gScore[neighbor] = tentative_gScore\n",
    "                fScore[neighbor] = gScore[neighbor] + h[neighbor]\n",
    "\n",
    "    # Open set is empty but goal was never reached\n",
    "    print(\"No path found to goal\")\n",
    "    return [], [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigation with Kalman Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**\n",
    "\n",
    "- Initial orient and position of Thymio\n",
    "- Map information including start and goal position\n",
    "- Control sequences from global path planning\n",
    "- Ground proximity sensors values\n",
    "- Thymio speed\n",
    "\n",
    "**Output**\n",
    "\n",
    "- Motion control signal for controlling movement\n",
    "- Estimated state from Kalman filter\n",
    "- Odometry information, i.e., estimated absolute position via proximity sensor data\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "- The filter can estimate the robot's X-Y translation with the proximity sensor data based on the linear model.\n",
    "- The motion interval is adjustable and can be partitioned more fine-grained to obtain better filter performance.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "- The incremental error of orient may cause the robot to neither move horizontally nor vertically. Simultaneously, the problem still exists even though the particle filter is employed, and more kinds of movement directions are introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key parameters**\n",
    "\n",
    "| Name               | Meaning                                                      | Type (Unit) | Global |\n",
    "| :------------------ | :------------------------------------------------------------ | :----------- | :------ |\n",
    "| `h_v_flag`         | robot orientation (vertical: 1; horizontal: 0)               | Bool        | Yes    |\n",
    "| `diff_orient`      | orient difference                                            | Float (rad) | No     |\n",
    "| `initial_orient`   | initial orient from measurement of camera                    | Float (rad) | Yes    |\n",
    "| `state_orient`     | the orient of robot through whole process of control         | Float (rad) | Yes    |\n",
    "| `h_v_flag`         | robot orientation (vertical: ; horizontal: )                 | Bool        | Yes    |\n",
    "| `lw_offset`        | the offset to compensate speeds of left wheel when step forward | Int         | Yes    |\n",
    "| `rw_offset`        | the offset to compensate speeds of right wheel when step forward | Int         | Yes    |\n",
    "| `rot_speed`        | the speed of wheel when turn left or right                   | Int         | Yes    |\n",
    "| `run_speed`        | the speed pf wheel when step forward                         | Int         | Yes    |\n",
    "| `forward_duration` | the running time of stepping forward                         | Float(s)    | Yes    |\n",
    "| `rot_duration`     | the running time of rotating                                 | Float(s)    | Yes    |\n",
    "| `unit_dis`         | the length of square of grid                                 | Float(cm)   | Yes    |\n",
    "| `mid_unit_dis`     | the length of transient stripe                               | Float(cm)   | Yes    |\n",
    "| `trans_thresh`     | the minimal threshold of reflected signal intensity to detect transition w.r.t gray to white and white to black | Int         | Yes    |\n",
    "| `x_pos_record`     | array of recorded X position from odometry                   | Float(cm)   | Yes    |\n",
    "| `x_pos_est`        | array of estimated X position from Kalman filter             | Float(cm)   | Yes    |\n",
    "| `inner_iter`       | the indicator of partition of one step, which can be used to improve precision of filter | Int         | No     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:54:39.411075Z",
     "start_time": "2020-12-05T19:54:39.394909Z"
    }
   },
   "outputs": [],
   "source": [
    "pi=math.pi\n",
    "\n",
    "## Finite State Machine, feed_forward_control\n",
    "######################\n",
    "lw_offset=0\n",
    "rw_offset=0\n",
    "rot_speed=125\n",
    "run_speed=235\n",
    "forward_duration=1\n",
    "speed_conv_factor = 0.03375;\n",
    "rot_duration=1.2\n",
    "unit_dis=8\n",
    "mid_unit_dis=0.5\n",
    "trans_thresh = 640\n",
    "\n",
    "err_orient=pi/36\n",
    "state_orient=0\n",
    "desired_orient=pi/2\n",
    "\n",
    "basic_moves= [(0, 1),(-1,0),(0,-1),(1,0)]\n",
    "basic_orients= ['North','West','South','East']\n",
    "basic_angle= [0.5*pi,pi,-0.5*pi,0]\n",
    "turn_left_flag=False\n",
    "turn_right_flag=False\n",
    "step_forward_flag=False\n",
    "h_dis_threshold=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:54:29.842441Z",
     "start_time": "2020-12-05T19:54:29.820309Z"
    }
   },
   "outputs": [],
   "source": [
    "########## orient calibrate with initial camera image\n",
    "def orient_calibrate(initial_orient,desired_orient):\n",
    "    diff=desired_orient-initial_orient\n",
    "    print('calibrated degree',diff*180/pi)\n",
    "    if diff>0:\n",
    "        turnleft(diff)\n",
    "    else:\n",
    "        turnright(-diff)\n",
    "    stopmotors()\n",
    "\n",
    "def stopmotors():\n",
    "    th.set_var(\"motor.left.target\", 0)\n",
    "    th.set_var(\"motor.right.target\", 0)\n",
    "\n",
    "def stepforward(forward_t):\n",
    "    global iter_com\n",
    "    th.set_var(\"motor.left.target\", run_speed + lw_offset)\n",
    "    th.set_var(\"motor.right.target\", run_speed + rw_offset)\n",
    "    time.sleep(forward_t)\n",
    "    step_forward_flag=False\n",
    "    sp=th[\"motor.left.target\"]\n",
    "    stopmotors()\n",
    "    return sp\n",
    "\n",
    "def turnleft(diff_orient):\n",
    "    global state_orient,h_v_flag\n",
    "    if h_v_flag==1:\n",
    "        h_v_flag=0\n",
    "    else:\n",
    "        h_v_flag=1\n",
    "    th.set_var(\"motor.left.target\", 2**16-rot_speed)\n",
    "    th.set_var(\"motor.right.target\", rot_speed)\n",
    "    time.sleep(diff_orient*rot_duration)\n",
    "    stopmotors()\n",
    "    state_orient=diff_orient+state_orient\n",
    "    turn_left_flag=False\n",
    "\n",
    "def turnright(diff_orient):\n",
    "    global state_orient,h_v_flag\n",
    "    if h_v_flag==1:\n",
    "        h_v_flag=0\n",
    "    else:\n",
    "        h_v_flag=1\n",
    "    th.set_var(\"motor.left.target\", rot_speed)\n",
    "    th.set_var(\"motor.right.target\", 2**16-rot_speed)\n",
    "    time.sleep(diff_orient*rot_duration)\n",
    "    stopmotors()\n",
    "    state_orient=state_orient-diff_orient\n",
    "    turn_right_flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- global_controller & kalman_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:54:42.083758Z",
     "start_time": "2020-12-05T19:54:42.049758Z"
    }
   },
   "outputs": [],
   "source": [
    "#################\n",
    "#global controller\n",
    "def global_controller(iter_com, inner_iter):\n",
    "    global run_flag\n",
    "    move_seq=dict(zip(basic_moves, basic_orients))\n",
    "    ang_seq=dict(zip(basic_moves, basic_angle))\n",
    "    global_path=np.load('optimalpath_global.npy')\n",
    "    # conversion of format of data from .py file \n",
    "    ctr_seq1=np.load('control_guide.npy')\n",
    "    ctr_seq=[]\n",
    "    for i in ctr_seq1:\n",
    "        i=tuple(i)\n",
    "        ctr_seq.insert(len(ctr_seq),i)\n",
    "    try:\n",
    "        #print('ctr',ctr_seq[iter_com])\n",
    "        cr_move=move_seq[ctr_seq[iter_com]]\n",
    "        \n",
    "        dir_move=ang_seq[ctr_seq[iter_com]]\n",
    "        #print('orient',dir_move)\n",
    "    except IndexError:\n",
    "        stopmotors()\n",
    "        run_flag=0\n",
    "        return run_flag\n",
    "    if inner_iter==0:\n",
    "        #print(dir_move)\n",
    "        #print('stateorient',state_orient)\n",
    "        diff_orient=state_orient-dir_move\n",
    "        #print('diff_orient',diff_orient)\n",
    "        if diff_orient>err_orient:\n",
    "            turnright(diff_orient)\n",
    "        if diff_orient<-err_orient:\n",
    "            turnleft(-diff_orient)\n",
    "####### without detection of local obstacles, global navigator.\n",
    "    h_dis = th[\"prox.horizontal\"][1:4]\n",
    "    h_sens=sum(h_dis)/len(h_dis)\n",
    "    if h_sens < h_dis_threshold:\n",
    "        duration=forward_duration\n",
    "        sp=run_speed\n",
    "        sp=stepforward(duration/3)\n",
    "\n",
    "    else:  # protect mode, and introduce local avoidance afterward\n",
    "        stopmotors()\n",
    "        time.sleep(0.1)\n",
    "        sp=0\n",
    "    \n",
    "    return sp\n",
    "\n",
    "############################ update map and add obstacle, local avoidance\n",
    "###########################  part of Q and R related to pos can be selected wrt para, to speed can be selected either through \n",
    "########## experiment or empirically. Two dimension Kalman filter.\n",
    "def kalman_filter(speed, g_sens_prev, g_sens, x_pos_last_trans, y_pos_last_trans, x_est_prev, y_est_prev, \n",
    "                  Px_est_prev, Py_est_prev, Q, h_v_flag,Ts):\n",
    "    A = np.array([[1, Ts], [0, 1]])\n",
    "    # update priori state and priori state error covariance\n",
    "    if h_v_flag:\n",
    "            x_est_a_priori = np.dot(A, x_est_prev)\n",
    "            Px_est_a_priori = np.dot(A, np.dot(Px_est_prev, A.T)) + Q\n",
    "            y_est_a_priori=y_est_prev\n",
    "            Py_est_a_priori=Py_est_prev\n",
    "    else:\n",
    "        y_est_a_priori = np.dot(A, y_est_prev)\n",
    "        Py_est_a_priori = np.dot(A, np.dot(Py_est_prev, A.T)) + Q\n",
    "        x_est_a_priori=x_est_prev\n",
    "        Px_est_a_priori=Px_est_prev\n",
    "    # XOR logic to detect transition\n",
    "    if ((g_sens < trans_thresh)^(g_sens_prev < trans_thresh)) :\n",
    "\n",
    "        stripe_width = unit_dis\n",
    "        # transition detected\n",
    "        if h_v_flag:\n",
    "            x_pos_last_trans = x_pos_last_trans + stripe_width;\n",
    "            y = np.array([x_pos_last_trans,speed*speed_conv_factor])\n",
    "            H = np.array([[1, 0],[0, 1]])\n",
    "            R = np.array([[rp, 0],[0, r_nu]])\n",
    "        else:\n",
    "            #update measurement\n",
    "            y_pos_last_trans = y_pos_last_trans + stripe_width;\n",
    "            y = np.array([y_pos_last_trans,speed*speed_conv_factor])\n",
    "            H = np.array([[1, 0],[0, 1]])\n",
    "            R = np.array([[rp, 0],[0, r_nu]])\n",
    "    else:\n",
    "        # no transition, use only the speed\n",
    "        y = speed*speed_conv_factor;\n",
    "        H = np.array([[0, 1]])\n",
    "        R = r_nu;\n",
    "\n",
    "    if h_v_flag:\n",
    "        # compute innovation\n",
    "        i = y - np.dot(H, x_est_a_priori);\n",
    "        S = np.dot(H, np.dot(Px_est_a_priori, H.T)) + R;\n",
    "        # compute optimal gain\n",
    "        K = np.dot(Px_est_a_priori, np.dot(H.T, np.linalg.inv(S)));\n",
    "        # update posterior estimated state\n",
    "        x_est = x_est_a_priori + np.dot(K,i);\n",
    "        y_est=np.array([y_est_prev[0],speed*speed_conv_factor]);\n",
    "        # update posterior state error covariance\n",
    "        Px_est = Px_est_a_priori - np.dot(K,np.dot(H, Px_est_a_priori));\n",
    "        Py_est=Py_est_prev\n",
    "    else:\n",
    "        i = y - np.dot(H, y_est_a_priori);\n",
    "        S = np.dot(H, np.dot(Py_est_a_priori, H.T)) + R;\n",
    "        K = np.dot(Py_est_a_priori, np.dot(H.T, np.linalg.inv(S)));\n",
    "        y_est = y_est_a_priori + np.dot(K,i);\n",
    "        x_est=np.array([x_est_prev[0],speed*speed_conv_factor]);\n",
    "        Py_est = Py_est_a_priori - np.dot(K,np.dot(H, Py_est_a_priori));\n",
    "        Px_est=Px_est_prev\n",
    "\n",
    "     \n",
    "    return x_pos_last_trans, y_pos_last_trans, x_est, y_est, Px_est, Py_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Map Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 4 A3 paper containing black and white grids to compose the map, where the grid size is 80mm x 80mm.\n",
    "\n",
    "In this part, Thymio is connected to the computer using a 3m cable.\n",
    "\n",
    "![](./img/without_Small.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:54:44.589405Z",
     "start_time": "2020-12-05T19:54:44.301400Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from viz_utilis import plot_curr_map\n",
    "\n",
    "w = 10\n",
    "h = 6\n",
    "plot_curr_map(w,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Towards the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test case1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map loading & goal setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:08:23.128567Z",
     "start_time": "2020-12-05T20:08:22.347045Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from viz_utilis import plotPathSW\n",
    "\n",
    "start=(1,0)\n",
    "goal=(3,2)\n",
    "global_map = np.zeros((10,6))\n",
    "path, control_guide = A_Star_4_direction(start, goal, global_map, len(global_map), len(global_map[0]))\n",
    "print(\"Path\\n\", path)\n",
    "print(\"Control guide\\n\", control_guide)\n",
    "experi_name = \"test1\"\n",
    "np.save(experi_name+'_optimalpath_global.npy',path)\n",
    "np.save(experi_name+'_control_guide.npy',control_guide)\n",
    "\n",
    "#plotPathSW(path, w, h)\n",
    "plotPathSW(path, w, h, experi_name, True)\n",
    "\n",
    "state_orient=0 #initial orientation\n",
    "desired_orient=pi/2 # desired orientation\n",
    "init_desired_orient = copy.deepcopy(desired_orient) # remember desired state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Move towards goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:34:32.361990Z",
     "start_time": "2020-12-05T19:34:20.637452Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Parameters\n",
    "# final goal\n",
    "x_goal=goal[0]*unit_dis\n",
    "y_goal=goal[1]*unit_dis\n",
    "\n",
    "EVAL=0.5\n",
    "h_v_flag=0\n",
    "# parameters from Kalman Filters\n",
    "qp = 0.0004 # variance on position state\n",
    "rp = 0.0025 # variance on position measurement\n",
    "r_nu=0.0615\n",
    "q_nu=0.0615\n",
    "Q= np.array([[qp, 0], [0, q_nu]])\n",
    "#the detailed parameters needs to be measured in practice.\n",
    "x_pos_last_trans=0;\n",
    "y_pos_last_trans=0;\n",
    "x_est_prev=np.array([0,0])\n",
    "y_est_prev=np.array([0,0])\n",
    "Px_est_prev=Q\n",
    "Py_est_prev=Q;\n",
    "\n",
    "# recording parameters\n",
    "iter_com=0\n",
    "bingo=0\n",
    "x_pos_record= []\n",
    "y_pos_record=[]\n",
    "x_pos_est= []\n",
    "y_pos_est=[]\n",
    "inner_iter=0\n",
    "\n",
    "## Action\n",
    "# calibrate init angle; # state_orient: initial orientation; # desired_orient: desired orientation\n",
    "orient_calibrate(state_orient,desired_orient)\n",
    "\n",
    "while bingo==0:\n",
    "    if inner_iter<3:\n",
    "        g_sens_prev=th[\"prox.ground.reflected\"]\n",
    "        g_sens_prev=sum(g_sens_prev)/len(g_sens_prev)\n",
    "        run_flag=global_controller(iter_com,inner_iter)\n",
    "        if run_flag==0:\n",
    "            break\n",
    "        \n",
    "        speed=250\n",
    "\n",
    "        Ts=1/3\n",
    "        g_sens=th[\"prox.ground.reflected\"]\n",
    "        g_sens=sum(g_sens)/len(g_sens)\n",
    "\n",
    "\n",
    "        x_pos_last_trans, y_pos_last_trans, x_est, y_est, Px_est, Py_est= kalman_filter(speed, g_sens_prev, g_sens, x_pos_last_trans, y_pos_last_trans, x_est_prev, y_est_prev, \n",
    "                      Px_est_prev, Py_est_prev, Q, h_v_flag,Ts)\n",
    "        x_est_prev=x_est \n",
    "        y_est_prev=y_est\n",
    "        Px_est_prev=Px_est\n",
    "        Py_est_prev=Py_est\n",
    "        x_pos_est.append(x_est)\n",
    "        y_pos_est.append(y_est)\n",
    "        x_pos_record.append(x_pos_last_trans)\n",
    "        y_pos_record.append(y_pos_last_trans)\n",
    "        print('iter',iter_com)\n",
    "        inner_iter=inner_iter+1\n",
    "    if inner_iter==3:\n",
    "        iter_com+=1\n",
    "        inner_iter=0\n",
    "    print('x_est',x_est)\n",
    "    print('y_est',y_est)\n",
    "    #print('pos_trans',x_pos_last_trans)\n",
    "    bingo=abs(x_goal-x_est[0])<EVAL and abs(y_goal-y_est[0])<EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Result ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:34:38.028437Z",
     "start_time": "2020-12-05T19:34:37.553147Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "from viz_utilis import plot_est_result_xy\n",
    "plot_est_result_xy(x_pos_est, y_pos_est, start, goal, init_state_orient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test case2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:10:14.775715Z",
     "start_time": "2020-12-05T20:10:13.920407Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from viz_utilis import plotPathSW\n",
    "\n",
    "start=(1,0)\n",
    "goal=(4,4)\n",
    "global_map = np.zeros((10,6))\n",
    "path, control_guide = A_Star_4_direction(start, goal, global_map, len(global_map), len(global_map[0]))\n",
    "print(\"Path\\n\", path)\n",
    "print(\"Control guide\\n\", control_guide)\n",
    "experi_name = \"test2\"\n",
    "np.save(\"./npy/\"+experi_name+'_optimalpath_global.npy',path)\n",
    "np.save(\"./npy/\"+experi_name+'_control_guide.npy',control_guide)\n",
    "\n",
    "#plotPathSW(path, w, h)\n",
    "plotPathSW(path, w, h, experi_name, True)\n",
    "\n",
    "state_orient=pi/2 #initial orientation\n",
    "desired_orient=pi/2 # desired orientation\n",
    "init_desired_orient = copy.deepcopy(desired_orient) # remember desired state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:55:33.138425Z",
     "start_time": "2020-12-05T19:55:16.418360Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Parameters\n",
    "# final goal\n",
    "x_goal=goal[0]*unit_dis\n",
    "y_goal=goal[1]*unit_dis\n",
    "\n",
    "EVAL=0.5\n",
    "h_v_flag=0\n",
    "# parameters from Kalman Filters\n",
    "qp = 0.0004 # variance on position state\n",
    "rp = 0.0025 # variance on position measurement\n",
    "r_nu=0.0615\n",
    "q_nu=0.0615\n",
    "Q= np.array([[qp, 0], [0, q_nu]])\n",
    "#the detailed parameters needs to be measured in practice.\n",
    "x_pos_last_trans=0;\n",
    "y_pos_last_trans=0;\n",
    "x_est_prev=np.array([0,0])\n",
    "y_est_prev=np.array([0,0])\n",
    "Px_est_prev=Q\n",
    "Py_est_prev=Q;\n",
    "\n",
    "# recording parameters\n",
    "iter_com=0\n",
    "bingo=0\n",
    "x_pos_record= []\n",
    "y_pos_record=[]\n",
    "x_pos_est= []\n",
    "y_pos_est=[]\n",
    "inner_iter=0\n",
    "\n",
    "## Action\n",
    "# calibrate init angle; # state_orient: initial orientation; # desired_orient: desired orientation\n",
    "orient_calibrate(state_orient,desired_orient)\n",
    "\n",
    "while bingo==0:\n",
    "    if inner_iter<3:\n",
    "        g_sens_prev=th[\"prox.ground.reflected\"]\n",
    "        g_sens_prev=sum(g_sens_prev)/len(g_sens_prev)\n",
    "        run_flag=global_controller(iter_com,inner_iter)\n",
    "        if run_flag==0:\n",
    "            break\n",
    "        \n",
    "        speed=250\n",
    "\n",
    "        Ts=1/3\n",
    "        g_sens=th[\"prox.ground.reflected\"]\n",
    "        g_sens=sum(g_sens)/len(g_sens)\n",
    "\n",
    "\n",
    "        x_pos_last_trans, y_pos_last_trans, x_est, y_est, Px_est, Py_est= kalman_filter(speed, g_sens_prev, g_sens, x_pos_last_trans, y_pos_last_trans, x_est_prev, y_est_prev, \n",
    "                      Px_est_prev, Py_est_prev, Q, h_v_flag,Ts)\n",
    "        x_est_prev=x_est \n",
    "        y_est_prev=y_est\n",
    "        Px_est_prev=Px_est\n",
    "        Py_est_prev=Py_est\n",
    "        x_pos_est.append(x_est)\n",
    "        y_pos_est.append(y_est)\n",
    "        x_pos_record.append(x_pos_last_trans)\n",
    "        y_pos_record.append(y_pos_last_trans)\n",
    "        print('iter',iter_com)\n",
    "        inner_iter=inner_iter+1\n",
    "    if inner_iter==3:\n",
    "        iter_com+=1\n",
    "        inner_iter=0\n",
    "    print('x_est',x_est)\n",
    "    print('y_est',y_est)\n",
    "    #print('pos_trans',x_pos_last_trans)\n",
    "    bingo=abs(x_goal-x_est[0])<EVAL and abs(y_goal-y_est[0])<EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:55:46.319619Z",
     "start_time": "2020-12-05T19:55:46.086300Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_est_result_xy(x_pos_est, y_pos_est, start, goal, init_desired_orient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test case3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:09:09.256271Z",
     "start_time": "2020-12-05T20:09:08.469503Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from viz_utilis import plotPathSW\n",
    "\n",
    "start=(1,1)\n",
    "goal=(7,3)\n",
    "global_map = np.zeros((10,6))\n",
    "path, control_guide = A_Star_4_direction(start, goal, global_map, len(global_map), len(global_map[0]))\n",
    "print(\"Path\\n\", path)\n",
    "print(\"Control guide\\n\", control_guide)\n",
    "experi_name = \"test3\"\n",
    "np.save(\"./npy/\"+experi_name+'_optimalpath_global.npy',path)\n",
    "np.save(\"./npy/\"+experi_name+'_control_guide.npy',control_guide)\n",
    "\n",
    "#plotPathSW(path, w, h)\n",
    "plotPathSW(path, w, h, experi_name, True)\n",
    "\n",
    "state_orient=pi/2 #initial orientation\n",
    "desired_orient=0 # desired orientation\n",
    "init_desired_orient = copy.deepcopy(desired_orient) # remember desired state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:48.291518Z",
     "start_time": "2020-12-05T19:59:30.619765Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Parameters\n",
    "# final goal\n",
    "x_goal=goal[0]*unit_dis\n",
    "y_goal=goal[1]*unit_dis\n",
    "\n",
    "EVAL=0.5\n",
    "h_v_flag=0\n",
    "# parameters from Kalman Filters\n",
    "qp = 0.0004 # variance on position state\n",
    "rp = 0.0025 # variance on position measurement\n",
    "r_nu=0.0615\n",
    "q_nu=0.0615\n",
    "Q= np.array([[qp, 0], [0, q_nu]])\n",
    "#the detailed parameters needs to be measured in practice.\n",
    "x_pos_last_trans=0;\n",
    "y_pos_last_trans=0;\n",
    "x_est_prev=np.array([0,0])\n",
    "y_est_prev=np.array([0,0])\n",
    "Px_est_prev=Q\n",
    "Py_est_prev=Q;\n",
    "\n",
    "# recording parameters\n",
    "iter_com=0\n",
    "bingo=0\n",
    "x_pos_record= []\n",
    "y_pos_record=[]\n",
    "x_pos_est= []\n",
    "y_pos_est=[]\n",
    "inner_iter=0\n",
    "\n",
    "## Action\n",
    "# calibrate init angle; # state_orient: initial orientation; # desired_orient: desired orientation\n",
    "orient_calibrate(state_orient,desired_orient)\n",
    "\n",
    "while bingo==0:\n",
    "    if inner_iter<3:\n",
    "        g_sens_prev=th[\"prox.ground.reflected\"]\n",
    "        g_sens_prev=sum(g_sens_prev)/len(g_sens_prev)\n",
    "        run_flag=global_controller(iter_com,inner_iter)\n",
    "        if run_flag==0:\n",
    "            break\n",
    "        \n",
    "        speed=250\n",
    "\n",
    "        Ts=1/3\n",
    "        g_sens=th[\"prox.ground.reflected\"]\n",
    "        g_sens=sum(g_sens)/len(g_sens)\n",
    "\n",
    "\n",
    "        x_pos_last_trans, y_pos_last_trans, x_est, y_est, Px_est, Py_est= kalman_filter(speed, g_sens_prev, g_sens, x_pos_last_trans, y_pos_last_trans, x_est_prev, y_est_prev, \n",
    "                      Px_est_prev, Py_est_prev, Q, h_v_flag,Ts)\n",
    "        x_est_prev=x_est \n",
    "        y_est_prev=y_est\n",
    "        Px_est_prev=Px_est\n",
    "        Py_est_prev=Py_est\n",
    "        x_pos_est.append(x_est)\n",
    "        y_pos_est.append(y_est)\n",
    "        x_pos_record.append(x_pos_last_trans)\n",
    "        y_pos_record.append(y_pos_last_trans)\n",
    "        print('iter',iter_com)\n",
    "        inner_iter=inner_iter+1\n",
    "    if inner_iter==3:\n",
    "        iter_com+=1\n",
    "        inner_iter=0\n",
    "    print('x_est',x_est)\n",
    "    print('y_est',y_est)\n",
    "    #print('pos_trans',x_pos_last_trans)\n",
    "    bingo=abs(x_goal-x_est[0])<EVAL and abs(y_goal-y_est[0])<EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:09:46.905250Z",
     "start_time": "2020-12-05T20:09:46.657102Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_est_result_xy(x_pos_est, y_pos_est, start, goal, init_desired_orient)\n",
    "np.save(\"./npy/x_pos_est_test3.npy\", x_pos_est)\n",
    "np.save(\"./npy/y_pos_est_test3.npy\", y_pos_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]    M. Ben-Ari and F. Mondada, *Elements of robotics*. Springer Nature, 2017.\n",
    "\n",
    "[2]    R. C. Gonzalez and R. E. Woods, *Digital Image Processing (4th Edition)*. Pearson, 2017.\n",
    "\n",
    "[3]    R. Siegwart, I. R. Nourbakhsh, and D. Scaramuzza, *Introduction to autonomous mobile robots*. MIT press, 2011.\n",
    "\n",
    "**Acknowledgment**\n",
    "\n",
    "The overall structure of the notebook borrows from the [GitHub Repo](https://github.com/gomandr/thymio-autonomous-navigation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291.675px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
